# localLLM
ì´ í”„ë¡œì íŠ¸ëŠ” [privateGPT](https://github.com/imartinez/privateGPT)ê¸°ë°˜í•´ì„œ ìˆ˜ì •ëœ [localGPT](https://github.com/PromtEngineer/localGPT)ì˜ ì½”ë“œë¥¼ ì´ìš©í•´ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.

### ğŸ’¡ í”„ë¡œì íŠ¸ ë‚´ìš©
- langchainì„ í†µí•´ ì›í•˜ëŠ” ë¬¸ì„œ(pdf,csv,dox ë“±)ì— ê¸°ë°˜í•˜ì—¬ ì‘ë‹µí•  ìˆ˜ ìˆëŠ” LLM(Large Language Model)
- localì—ì„œ LLMì„ ì‚¬ìš©í•¨ìœ¼ë¡œì¨, ë°ì´í„° ìœ ì¶œì—†ì´ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ê°€ëŠ¥í•´ì§
- ëª¨ë¸ì€ Vicuna-7Bë¥¼ ì‚¬ìš©í•˜ì˜€ê³ , InstructorEmbeddingsì„ ì‚¬ìš©í•˜ì˜€ìŒ
- ê·¸ ì™¸, í”„ë¡œì íŠ¸ ë‚´ì—ì„œ LangChain, GPT4All, LlamaCpp, Chroma, SentenceTransformersê°€ ì‚¬ìš©ë˜ì—ˆìŒ
![image](https://github.com/pphhyy0620/localLLM/assets/122515100/3d0a2e87-6977-4ec2-9b26-153197aa3c9c)



# Environment Setup
ê°€ìƒí™˜ê²½ ìƒì„±

 ```
 conda create -n localllm python==3.10
```

ê°€ìƒí™˜ê²½ í™œì„±í™”
 ```
conda activate localllm
 ```
git clone 
 ```
git clone https://github.com/pphhyy0620/localLLM.git
 ``` 
path ì§€ì •
 ``` 
cd localLLM
```
í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
```
pip install -r requirements.txt
```
ë¬¸ì„œ ë¡œë“œ ë° ë¶„í•  (GPU, CPU í™˜ê²½ì— ë§ê²Œ ì‚¬ìš©í•˜ì‹œë©´ ë  ê²ƒ ê°™ìŠµë‹ˆë‹¤.)
```
# GPU
python ingest.py
# CPU
python ingest.py --device_type cpu
```
ë¬¸ì„œ ê¸°ë°˜ QA ì‹¤í–‰
```
# GPU
python local_LLM.py
# CPU
python local_LLM.py --device_type cpu
```
- ì‹¤í–‰ê²°ê³¼ ì•„ë˜ì™€ ê°™ì´ ë‚˜ì˜¤ê³ , ê´€ë ¨ ì§ˆë¬¸ì„ í•˜ì‹œë©´ ë¬¸ì„œì— ê¸°ë°˜í•˜ì—¬ ë‹µë³€í•˜ê²Œ ë©ë‹ˆë‹¤.
![image](https://github.com/pphhyy0620/localLLM/assets/122515100/9f85e359-ccbc-49b0-b2ac-b7cb32c3d09b)

- ì¢…ë£Œí•˜ê³  ì‹¶ë‹¤ë©´ `exit`ë¥¼ queryì— ì ìœ¼ì‹œë©´ ì¢…ë£Œë©ë‹ˆë‹¤.


